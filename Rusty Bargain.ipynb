{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split \n",
    "from sklearn.preprocessing import MaxAbsScaler, OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Introduction](#1)\n",
    "\n",
    "[Data Description](#2)\n",
    "\n",
    "[Data Preparation](#3)\n",
    "\n",
    "- [Checking Duplicates, Data Types, and Column Names](#3.1)\n",
    "- [Exploratory Data Analysis](#3.2)\n",
    "- [Encoding the Dataframe](#3.3)\n",
    "\n",
    "[Model Training](#4)\n",
    "- [Linear Regression Model](#4.1)\n",
    "- [Decision Tree Model, No Hyperparameter Tuning](#4.2)\n",
    "- [Decision Tree Model, With Hyperparameter Tuning](#4.3)\n",
    "- [Random Forest Model, No Hyperparameter Tuning](#4.4)\n",
    "- [Random Forest Model, With Hyperparameter Tuning](#4.5)\n",
    "- [CatBoost Regressor, No Hyperparameter Tuning](#4.6)\n",
    "- [CatBoost Regressor, With Hyperparameter Tuning](#4.7)\n",
    "- [LightGBM Regressor, No Hyperparameter Tuning](#4.8)\n",
    "- [LightGBM Regressor, With Hyperparameter Tuning](#4.9)\n",
    "- [XGB Regressor, No Hyperparameter Tuning](#4.10)\n",
    "- [XGB Regressor, With Hyperparameter Tuning](#4.11)\n",
    "\n",
    "[Model Analysis](#5)\n",
    "\n",
    "[Conclusion](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id=1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain is a used car sales company that is developing an app to attract new customers. \n",
    "\n",
    "The purpose of the app is to quickly determine the market value of a customer's used car, and it uses historical data about cars (specifically, the specifications, the trim versions, and the prices) to accomplish this. \n",
    "\n",
    "My responsibility is to build the model that the app uses to determine the value of a given used car.\n",
    "\n",
    "Rusty Bargain is interested in the following aspects of my model:\n",
    "\n",
    "- The accuracy of the predicted prices \n",
    "- The speed at which the model makes its predictions\n",
    "- The time required for training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help me build a sufficiently good model, I will do the following:\n",
    "\n",
    "(1) Download and look at the given dataset to determine if any preprocessing is needed.\n",
    "\n",
    "(2) Train different machine learning models with various hyperparameters. Specifically, I will compare gradient boosting methods (LightGBM, CatBoost, and XGBoost) with decision tree, random forest, and linear regression models.\n",
    "\n",
    "(3) Analyze both the speed and the quality of the models.\n",
    "\n",
    "The following are some additional notes about how this project will be conducted:\n",
    "- The RMSE (root mean square error) metric will be used to evaluate the models.\n",
    "- Linear regression is not very good for hyperparameter tuning, but it is perfect for doing a sanity check of other methods.\n",
    "- I will use the **%%time** command to find the execution time of my models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description <a id=2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, as it is given to me, has the following features and target.\n",
    "\n",
    "**Features**\n",
    "\n",
    "DateCrawled — The date the profile of the vehicle was downloaded from the database\n",
    "\n",
    "VehicleType — The vehicle's body type\n",
    "\n",
    "RegistrationYear — The vehicle's registration year\n",
    "\n",
    "Gearbox — The gearbox type of the vehicle\n",
    "\n",
    "Power — The horsepower of the vehicle\n",
    "\n",
    "Model — The vehicle's model\n",
    "\n",
    "Mileage — The vehicle's mileage (in kilometers)\n",
    "\n",
    "RegistrationMonth — The vehicle's registration month\n",
    "\n",
    "FuelType — The vehicle's fuel type\n",
    "\n",
    "Brand — The vehicle's brand\n",
    "\n",
    "NotRepaired — Has the vehicle been repaired or not\n",
    "\n",
    "DateCreated — The date of the vehicle's profile creation\n",
    "\n",
    "NumberOfPictures — The number of pictures of the vehicle\n",
    "\n",
    "PostalCode — The postal code of the vehicle's profile's owner\n",
    "\n",
    "LastSeen — The date of the last activity of the user\n",
    "\n",
    "**Target**\n",
    "\n",
    "Price — The price of the used vehicle in euros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation <a id=3></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder if there are any rows in the dataframe that are exact duplicates. \n",
    "\n",
    "If so, then they should be dropped because it is incredibly unlikely that two or more distinct vehicles would have the exact same values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking Duplicates, Data Types, and Column Names** <a id=3.1></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14266</th>\n",
       "      <td>21/03/2016 19:06</td>\n",
       "      <td>5999</td>\n",
       "      <td>small</td>\n",
       "      <td>2009</td>\n",
       "      <td>manual</td>\n",
       "      <td>80</td>\n",
       "      <td>polo</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>21/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>65529</td>\n",
       "      <td>05/04/2016 20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27568</th>\n",
       "      <td>23/03/2016 10:38</td>\n",
       "      <td>12200</td>\n",
       "      <td>bus</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>125</td>\n",
       "      <td>zafira</td>\n",
       "      <td>40000</td>\n",
       "      <td>10</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>opel</td>\n",
       "      <td>no</td>\n",
       "      <td>23/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>26629</td>\n",
       "      <td>05/04/2016 07:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31599</th>\n",
       "      <td>03/04/2016 20:41</td>\n",
       "      <td>4950</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2003</td>\n",
       "      <td>auto</td>\n",
       "      <td>170</td>\n",
       "      <td>e_klasse</td>\n",
       "      <td>150000</td>\n",
       "      <td>4</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>no</td>\n",
       "      <td>03/04/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>48432</td>\n",
       "      <td>05/04/2016 21:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33138</th>\n",
       "      <td>07/03/2016 20:45</td>\n",
       "      <td>10900</td>\n",
       "      <td>convertible</td>\n",
       "      <td>2005</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>clk</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>no</td>\n",
       "      <td>07/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>61200</td>\n",
       "      <td>21/03/2016 03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43656</th>\n",
       "      <td>13/03/2016 20:48</td>\n",
       "      <td>4200</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2003</td>\n",
       "      <td>manual</td>\n",
       "      <td>105</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>10</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>13/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>14482</td>\n",
       "      <td>13/03/2016 20:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349709</th>\n",
       "      <td>03/04/2016 20:52</td>\n",
       "      <td>700</td>\n",
       "      <td>small</td>\n",
       "      <td>1999</td>\n",
       "      <td>manual</td>\n",
       "      <td>60</td>\n",
       "      <td>ibiza</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>petrol</td>\n",
       "      <td>seat</td>\n",
       "      <td>yes</td>\n",
       "      <td>03/04/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6268</td>\n",
       "      <td>05/04/2016 21:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351555</th>\n",
       "      <td>26/03/2016 16:54</td>\n",
       "      <td>3150</td>\n",
       "      <td>bus</td>\n",
       "      <td>2003</td>\n",
       "      <td>manual</td>\n",
       "      <td>86</td>\n",
       "      <td>transit</td>\n",
       "      <td>150000</td>\n",
       "      <td>11</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>ford</td>\n",
       "      <td>no</td>\n",
       "      <td>26/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>96148</td>\n",
       "      <td>02/04/2016 07:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352384</th>\n",
       "      <td>15/03/2016 21:54</td>\n",
       "      <td>5900</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2006</td>\n",
       "      <td>manual</td>\n",
       "      <td>129</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>petrol</td>\n",
       "      <td>bmw</td>\n",
       "      <td>no</td>\n",
       "      <td>15/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>92526</td>\n",
       "      <td>20/03/2016 21:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353057</th>\n",
       "      <td>05/03/2016 14:16</td>\n",
       "      <td>9500</td>\n",
       "      <td>small</td>\n",
       "      <td>2013</td>\n",
       "      <td>manual</td>\n",
       "      <td>105</td>\n",
       "      <td>ibiza</td>\n",
       "      <td>40000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>seat</td>\n",
       "      <td>no</td>\n",
       "      <td>04/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>61381</td>\n",
       "      <td>05/04/2016 19:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353727</th>\n",
       "      <td>20/03/2016 17:56</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bmw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>42329</td>\n",
       "      <td>07/04/2016 00:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateCrawled  Price  VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "14266   21/03/2016 19:06   5999        small              2009  manual     80   \n",
       "27568   23/03/2016 10:38  12200          bus              2011  manual    125   \n",
       "31599   03/04/2016 20:41   4950        wagon              2003    auto    170   \n",
       "33138   07/03/2016 20:45  10900  convertible              2005    auto    163   \n",
       "43656   13/03/2016 20:48   4200        sedan              2003  manual    105   \n",
       "...                  ...    ...          ...               ...     ...    ...   \n",
       "349709  03/04/2016 20:52    700        small              1999  manual     60   \n",
       "351555  26/03/2016 16:54   3150          bus              2003  manual     86   \n",
       "352384  15/03/2016 21:54   5900        wagon              2006  manual    129   \n",
       "353057  05/03/2016 14:16   9500        small              2013  manual    105   \n",
       "353727  20/03/2016 17:56      1          NaN              2000     NaN      0   \n",
       "\n",
       "           Model  Mileage  RegistrationMonth  FuelType          Brand  \\\n",
       "14266       polo   125000                  5    petrol     volkswagen   \n",
       "27568     zafira    40000                 10  gasoline           opel   \n",
       "31599   e_klasse   150000                  4  gasoline  mercedes_benz   \n",
       "33138        clk   125000                  5    petrol  mercedes_benz   \n",
       "43656       golf   150000                 10  gasoline     volkswagen   \n",
       "...          ...      ...                ...       ...            ...   \n",
       "349709     ibiza   150000                 12    petrol           seat   \n",
       "351555   transit   150000                 11  gasoline           ford   \n",
       "352384       3er   150000                 12    petrol            bmw   \n",
       "353057     ibiza    40000                  5    petrol           seat   \n",
       "353727       NaN   150000                  0       NaN            bmw   \n",
       "\n",
       "       NotRepaired       DateCreated  NumberOfPictures  PostalCode  \\\n",
       "14266           no  21/03/2016 00:00                 0       65529   \n",
       "27568           no  23/03/2016 00:00                 0       26629   \n",
       "31599           no  03/04/2016 00:00                 0       48432   \n",
       "33138           no  07/03/2016 00:00                 0       61200   \n",
       "43656           no  13/03/2016 00:00                 0       14482   \n",
       "...            ...               ...               ...         ...   \n",
       "349709         yes  03/04/2016 00:00                 0        6268   \n",
       "351555          no  26/03/2016 00:00                 0       96148   \n",
       "352384          no  15/03/2016 00:00                 0       92526   \n",
       "353057          no  04/03/2016 00:00                 0       61381   \n",
       "353727         NaN  20/03/2016 00:00                 0       42329   \n",
       "\n",
       "                LastSeen  \n",
       "14266   05/04/2016 20:47  \n",
       "27568   05/04/2016 07:44  \n",
       "31599   05/04/2016 21:17  \n",
       "33138   21/03/2016 03:45  \n",
       "43656   13/03/2016 20:48  \n",
       "...                  ...  \n",
       "349709  05/04/2016 21:47  \n",
       "351555  02/04/2016 07:47  \n",
       "352384  20/03/2016 21:17  \n",
       "353057  05/04/2016 19:18  \n",
       "353727  07/04/2016 00:46  \n",
       "\n",
       "[262 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[main_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow... I don't know how the dataframe ended up having 262 duplicated rows, but whatever the reason, the next line drops them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354107 entries, 0 to 354106\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354107 non-null  object\n",
      " 1   Price              354107 non-null  int64 \n",
      " 2   VehicleType        316623 non-null  object\n",
      " 3   RegistrationYear   354107 non-null  int64 \n",
      " 4   Gearbox            334277 non-null  object\n",
      " 5   Power              354107 non-null  int64 \n",
      " 6   Model              334406 non-null  object\n",
      " 7   Mileage            354107 non-null  int64 \n",
      " 8   RegistrationMonth  354107 non-null  int64 \n",
      " 9   FuelType           321218 non-null  object\n",
      " 10  Brand              354107 non-null  object\n",
      " 11  NotRepaired        282962 non-null  object\n",
      " 12  DateCreated        354107 non-null  object\n",
      " 13  NumberOfPictures   354107 non-null  int64 \n",
      " 14  PostalCode         354107 non-null  int64 \n",
      " 15  LastSeen           354107 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.2+ MB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the Dtypes seems appropriate for their corresponding columns, which is great! The only exceptions are **DateCrawled**, **DateCreated**, and **LastSeen**, which are better off having Dtype **datetime64** instead of merely **object**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['DateCrawled'] = pd.to_datetime(main_df['DateCrawled'], format = '%d/%m/%Y %H:%M')\n",
    "main_df['DateCreated'] = pd.to_datetime(main_df['DateCreated'], format = '%d/%m/%Y %H:%M')\n",
    "main_df['LastSeen'] = pd.to_datetime(main_df['LastSeen'], format = '%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem I noticed is that the column names are not in snake_case. The next line converts them into snake_case because this format is standard practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.rename(columns = {'DateCrawled': 'date_crawled', \n",
    "                                    'Price': 'price',\n",
    "                                    'VehicleType': 'vehicle_type',\n",
    "                                    'RegistrationYear': 'registration_year',\n",
    "                                    'Gearbox': 'gear_box',\n",
    "                                    'Power': 'horsepower',\n",
    "                                    'Model': 'model',\n",
    "                                    'Mileage': 'mileage',\n",
    "                                    'RegistrationMonth': 'registration_month',\n",
    "                                    'FuelType': 'fuel_type',\n",
    "                                    'Brand': 'brand',\n",
    "                                    'NotRepaired': 'not_repaired',\n",
    "                                    'DateCreated': 'date_created',\n",
    "                                    'NumberOfPictures': 'number_of_pictures',\n",
    "                                    'PostalCode': 'postal_code',\n",
    "                                    'LastSeen': 'last_seen'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I not only converted the column name **Power** to snake_case, I also changed its name to **horsepower** to be more specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many columns, I think it is a good idea to rearrange the columns to be in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.sort_index(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only exception I will make to the columns being in alphabetical order is that I would like for the **price** column to be last, since it seems logical for the target to appear last in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data = main_df['price'].copy()\n",
    "\n",
    "main_df = main_df.drop('price', axis = 1)\n",
    "\n",
    "main_df['price'] = price_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working on any project, it is common for me to display a random sample of rows so that I know what the dataset \"looks like\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>date_created</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>gear_box</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>mileage</th>\n",
       "      <th>model</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>number_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106919</th>\n",
       "      <td>audi</td>\n",
       "      <td>2016-03-06 01:57:00</td>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>petrol</td>\n",
       "      <td>manual</td>\n",
       "      <td>125</td>\n",
       "      <td>2016-03-06 08:38:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>a6</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>89079</td>\n",
       "      <td>10</td>\n",
       "      <td>1998</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278981</th>\n",
       "      <td>bmw</td>\n",
       "      <td>2016-03-15 21:47:00</td>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>petrol</td>\n",
       "      <td>manual</td>\n",
       "      <td>150</td>\n",
       "      <td>2016-03-17 18:47:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>3er</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>59889</td>\n",
       "      <td>11</td>\n",
       "      <td>1998</td>\n",
       "      <td>sedan</td>\n",
       "      <td>3199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6923</th>\n",
       "      <td>ford</td>\n",
       "      <td>2016-03-30 11:48:00</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>manual</td>\n",
       "      <td>143</td>\n",
       "      <td>2016-04-07 02:44:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>s_max</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>51109</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>bus</td>\n",
       "      <td>9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142218</th>\n",
       "      <td>toyota</td>\n",
       "      <td>2016-03-20 13:53:00</td>\n",
       "      <td>2016-03-20</td>\n",
       "      <td>petrol</td>\n",
       "      <td>manual</td>\n",
       "      <td>87</td>\n",
       "      <td>2016-03-25 13:45:00</td>\n",
       "      <td>90000</td>\n",
       "      <td>yaris</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>51149</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>small</td>\n",
       "      <td>4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125307</th>\n",
       "      <td>bmw</td>\n",
       "      <td>2016-04-04 16:37:00</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>manual</td>\n",
       "      <td>150</td>\n",
       "      <td>2016-04-04 16:37:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>3er</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>39116</td>\n",
       "      <td>12</td>\n",
       "      <td>2004</td>\n",
       "      <td>sedan</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285899</th>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>2016-03-28 20:42:00</td>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>petrol</td>\n",
       "      <td>auto</td>\n",
       "      <td>170</td>\n",
       "      <td>2016-04-07 02:47:00</td>\n",
       "      <td>125000</td>\n",
       "      <td>e_klasse</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>40667</td>\n",
       "      <td>7</td>\n",
       "      <td>1999</td>\n",
       "      <td>sedan</td>\n",
       "      <td>3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121459</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>2016-03-26 15:42:00</td>\n",
       "      <td>2016-03-26</td>\n",
       "      <td>petrol</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>2016-04-06 03:17:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>golf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>29525</td>\n",
       "      <td>6</td>\n",
       "      <td>1994</td>\n",
       "      <td>convertible</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206832</th>\n",
       "      <td>bmw</td>\n",
       "      <td>2016-03-08 19:53:00</td>\n",
       "      <td>2016-03-08</td>\n",
       "      <td>petrol</td>\n",
       "      <td>auto</td>\n",
       "      <td>171</td>\n",
       "      <td>2016-03-09 11:45:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>28832</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178542</th>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>2016-03-15 00:57:00</td>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>auto</td>\n",
       "      <td>143</td>\n",
       "      <td>2016-03-27 18:44:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>e_klasse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>99974</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311256</th>\n",
       "      <td>renault</td>\n",
       "      <td>2016-03-22 16:56:00</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>petrol</td>\n",
       "      <td>manual</td>\n",
       "      <td>95</td>\n",
       "      <td>2016-03-22 17:40:00</td>\n",
       "      <td>150000</td>\n",
       "      <td>megane</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>47877</td>\n",
       "      <td>12</td>\n",
       "      <td>2001</td>\n",
       "      <td>wagon</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                brand        date_crawled date_created fuel_type gear_box  \\\n",
       "106919           audi 2016-03-06 01:57:00   2016-03-06    petrol   manual   \n",
       "278981            bmw 2016-03-15 21:47:00   2016-03-15    petrol   manual   \n",
       "6923             ford 2016-03-30 11:48:00   2016-03-30  gasoline   manual   \n",
       "142218         toyota 2016-03-20 13:53:00   2016-03-20    petrol   manual   \n",
       "125307            bmw 2016-04-04 16:37:00   2016-04-04  gasoline   manual   \n",
       "285899  mercedes_benz 2016-03-28 20:42:00   2016-03-28    petrol     auto   \n",
       "121459     volkswagen 2016-03-26 15:42:00   2016-03-26    petrol   manual   \n",
       "206832            bmw 2016-03-08 19:53:00   2016-03-08    petrol     auto   \n",
       "178542  mercedes_benz 2016-03-15 00:57:00   2016-03-15  gasoline     auto   \n",
       "311256        renault 2016-03-22 16:56:00   2016-03-22    petrol   manual   \n",
       "\n",
       "        horsepower           last_seen  mileage     model not_repaired  \\\n",
       "106919         125 2016-03-06 08:38:00   150000        a6           no   \n",
       "278981         150 2016-03-17 18:47:00   150000       3er           no   \n",
       "6923           143 2016-04-07 02:44:00   150000     s_max           no   \n",
       "142218          87 2016-03-25 13:45:00    90000     yaris           no   \n",
       "125307         150 2016-04-04 16:37:00   150000       3er           no   \n",
       "285899         170 2016-04-07 02:47:00   125000  e_klasse           no   \n",
       "121459          75 2016-04-06 03:17:00   150000      golf          NaN   \n",
       "206832         171 2016-03-09 11:45:00   150000       NaN           no   \n",
       "178542         143 2016-03-27 18:44:00   150000  e_klasse          NaN   \n",
       "311256          95 2016-03-22 17:40:00   150000    megane           no   \n",
       "\n",
       "        number_of_pictures  postal_code  registration_month  \\\n",
       "106919                   0        89079                  10   \n",
       "278981                   0        59889                  11   \n",
       "6923                     0        51109                   4   \n",
       "142218                   0        51149                   2   \n",
       "125307                   0        39116                  12   \n",
       "285899                   0        40667                   7   \n",
       "121459                   0        29525                   6   \n",
       "206832                   0        28832                   3   \n",
       "178542                   0        99974                   1   \n",
       "311256                   0        47877                  12   \n",
       "\n",
       "        registration_year vehicle_type  price  \n",
       "106919               1998        sedan   1200  \n",
       "278981               1998        sedan   3199  \n",
       "6923                 2008          bus   9399  \n",
       "142218               2008        small   4350  \n",
       "125307               2004        sedan   3999  \n",
       "285899               1999        sedan   3650  \n",
       "121459               1994  convertible   2200  \n",
       "206832               1998        sedan   1900  \n",
       "178542               2002        wagon   2100  \n",
       "311256               2001        wagon    900  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis** <a id=3.2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at each column, except the date and postal code columns, to see if there are any unusual values. For the more quantitative features, I use the **describe** function, whereas for the more categorical features I use **value_counts()**.\n",
    "\n",
    "The reason why the three date columns will not be analyzed is because the purpose of the app is to quickly determine the market value of a customer's used car, and at the time when the customer is entering the details about their car into the app, the **DateCrawled**, **DateCreated**, and **LastSeen** values would simply not exist yet. (Actually, maybe the **LastSeen** value might exist if the customer is a returner, but it certainly would not exist if the customer is new.)\n",
    "\n",
    "For the same reason, the three date columns will not be used to train the models.\n",
    "\n",
    "As for postal code, where the customer lives should not affect the price of the car. In fact, the next line shows that there is virtually 0 correlation between the postal code values and the prices. For this reason, I will not use the **postal_code** column to train the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the postal code of a customer and the price of the car of the customer is about 0.08\n"
     ]
    }
   ],
   "source": [
    "print('The correlation between the postal code of a customer and the price of the car of the customer is about',\n",
    "     round(main_df['postal_code'].corr(main_df['price']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alfa_romeo         2311\n",
       "audi              29439\n",
       "bmw               36881\n",
       "chevrolet          1751\n",
       "chrysler           1439\n",
       "citroen            5143\n",
       "dacia               898\n",
       "daewoo              542\n",
       "daihatsu            806\n",
       "fiat               9634\n",
       "ford              25163\n",
       "honda              2817\n",
       "hyundai            3583\n",
       "jaguar              505\n",
       "jeep                677\n",
       "kia                2463\n",
       "lada                225\n",
       "lancia              471\n",
       "land_rover          545\n",
       "mazda              5611\n",
       "mercedes_benz     32025\n",
       "mini               3201\n",
       "mitsubishi         3022\n",
       "nissan             4936\n",
       "opel              39902\n",
       "peugeot           10988\n",
       "porsche             758\n",
       "renault           17915\n",
       "rover               486\n",
       "saab                526\n",
       "seat               6901\n",
       "skoda              5490\n",
       "smart              5241\n",
       "sonstige_autos     3373\n",
       "subaru              762\n",
       "suzuki             2320\n",
       "toyota             4601\n",
       "trabant             589\n",
       "volkswagen        76960\n",
       "volvo              3207\n",
       "Name: brand, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['brand'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing unusual with this column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petrol      216161\n",
       "gasoline     98658\n",
       "lpg           5307\n",
       "cng            565\n",
       "hybrid         233\n",
       "other          204\n",
       "electric        90\n",
       "Name: fuel_type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['fuel_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing unusual with their column either! However, I did notice that this is one of the columns that has null values. It would be very difficult, if not impossible, to figure out which fuel type each null value is meant to be, so instead I will fill the null values with the word \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['fuel_type'] = main_df['fuel_type'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manual    268034\n",
       "auto       66243\n",
       "Name: gear_box, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['gear_box'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that there are far more vehicles with manual gear boxes than automatic because it is only in recent years that automatic gear boxes have become more common than manual in some parts of the world.\n",
    "\n",
    "I noticed that this is one of the columns that has null values. It would be very difficult, if not impossible, to figure out which of the two gear boxes each null value is meant to be, so instead I will fill the null values with the word \"unknown\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['gear_box'] = main_df['gear_box'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    354107.000000\n",
       "mean        110.089651\n",
       "std         189.914972\n",
       "min           0.000000\n",
       "25%          69.000000\n",
       "50%         105.000000\n",
       "75%         143.000000\n",
       "max       20000.000000\n",
       "Name: horsepower, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['horsepower'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column has both unusually small and unusually large horsepower values. There is at least one car in the dataframe with a horsepower of 0, which is impossible, and there is at least one car with a horsepower of 20,000 which is also impossible.\n",
    "\n",
    "When Henry Ford introduced the Ford Model T in 1908, even those had a horsepower value of at least 20. On the flip side, I think any car whose apparent horsepower value is greater than 500 should be viewed as suspicious because even 500 is a rare horsepower value, a value one would probably only see in high-end vehicles.\n",
    "\n",
    "How many cars have \"suspicious\" horsepower values? Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 40635 cars that apparently have a horsepower less than 20.\n",
      "The dataframe has 459 cars that apparently have a horsepower greater than 500.\n"
     ]
    }
   ],
   "source": [
    "print('The dataframe has', len(main_df[main_df['horsepower'] < 20]), \n",
    "      'cars that apparently have a horsepower less than 20.')\n",
    "\n",
    "print('The dataframe has', len(main_df[main_df['horsepower'] > 500]), \n",
    "      'cars that apparently have a horsepower greater than 500.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, there are a lot of cars that have \"suspicious\" horsepower values (especially suspiciously low horsepowers)!\n",
    "\n",
    "I do not want to drop these rows because 40,635 + 459 = 41,094 is a lot of data. Instead, I will group the dataframe by **brand**, **model**, and **vehicle_type** and find the median horsepower value from grouping this way.\n",
    "\n",
    "I will also apply a lambda function that replaces the values less than 20 or greater than 500 with the corresponding median values.\n",
    "\n",
    "However, before I do this I must address the fact that the **model** and **vehicle_type** columns have null values. I could drop the rows with a null **model** and/or **vehicle_type** value, but that would risk losing a lot of data. Instead, I will fill these null values with the word \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['model'] = main_df['model'].fillna('unknown')\n",
    "main_df['vehicle_type'] = main_df['vehicle_type'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use **groupby** and the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_hp = main_df.groupby(['brand', 'model', 'vehicle_type'])['horsepower'].median().reset_index()\n",
    "\n",
    "main_df = pd.merge(main_df, median_hp, on = ['brand', 'model', 'vehicle_type'], suffixes = ('', '_median'))\n",
    "\n",
    "main_df['horsepower'] = main_df.apply(lambda row: row['horsepower_median'] \n",
    "                                       if ((row['horsepower'] < 20) or (row['horsepower'] > 500))\n",
    "                                       else row['horsepower'], axis = 1)\n",
    "\n",
    "main_df = main_df.drop(columns = ['horsepower_median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    354107.000000\n",
       "mean        116.533983\n",
       "std          55.045584\n",
       "min           0.000000\n",
       "25%          75.000000\n",
       "50%         109.000000\n",
       "75%         143.000000\n",
       "max        5000.000000\n",
       "Name: horsepower, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['horsepower'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lambda function definitely changed the summary statistics of the **horsepower** column, but somehow there is still at least one car with a horsepower value less than 20 (specifically, 0) and at least one car with a horsepower value more than 500 (specifically, 5000). This is likely because certain \"groups\" of cars, unfortunately, have unusually low or unusually high median horsepower values. How many cars still have \"suspicious\" horsepower values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe (still) has 3656 cars that apparently have a horsepower less than 20.\n",
      "The dataframe (still) has 7 cars that apparently have a horsepower greater than 500.\n"
     ]
    }
   ],
   "source": [
    "print('The dataframe (still) has', len(main_df[main_df['horsepower'] < 20]), \n",
    "      'cars that apparently have a horsepower less than 20.')\n",
    "\n",
    "print('The dataframe (still) has', len(main_df[main_df['horsepower'] > 500]), \n",
    "      'cars that apparently have a horsepower greater than 500.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am surprised that there are still 3,656 + 7 = 3,663 rows with such horsepower values, but thankfully this is far fewer than the 41,094 I had before. So much fewer to the point that I think it is reasonable to drop these 3,663 rows from the dataframe entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    350444.000000\n",
       "mean        117.699363\n",
       "std          52.640634\n",
       "min          20.000000\n",
       "25%          75.000000\n",
       "50%         109.000000\n",
       "75%         143.000000\n",
       "max         500.000000\n",
       "Name: horsepower, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = main_df[(main_df['horsepower'] >= 20) & (main_df['horsepower'] <= 500)]\n",
    "main_df['horsepower'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    350444.000000\n",
       "mean     128571.954435\n",
       "std       37409.230260\n",
       "min        5000.000000\n",
       "25%      125000.000000\n",
       "50%      150000.000000\n",
       "75%      150000.000000\n",
       "max      150000.000000\n",
       "Name: mileage, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['mileage'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values make sense. One can expect that the majority of used cars being sold have a high mileage, but it also makes sense for a small percentage of them to have low mileage, e.g. the one(s) with the minimum mileage value of 5,000. The low values make sense because some people deliberately use their high-value used cars gently in order to sell them for a high price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "golf                  29215\n",
       "other                 23832\n",
       "3er                   19744\n",
       "unknown               17625\n",
       "polo                  13057\n",
       "                      ...  \n",
       "serie_2                   6\n",
       "kalina                    6\n",
       "rangerover                3\n",
       "serie_3                   3\n",
       "range_rover_evoque        2\n",
       "Name: model, Length: 250, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column does not appear to have anything unusual about it. Intuitively, it makes sense that some models are far more common than others because it is not unheard of for car companies to release limited edition models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     246243\n",
       "yes     35808\n",
       "Name: not_repaired, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['not_repaired'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, it is very awkward (and possibly misleading) for a column name to use the word \"not\". I will rename this column to **is_repaired**, and make the **yes** and **no** values trade places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.rename(columns = {'not_repaired': 'is_repaired'})\n",
    "\n",
    "main_df['is_repaired'] = main_df['is_repaired'].replace('yes', 'change_to_no')\n",
    "main_df['is_repaired'] = main_df['is_repaired'].replace('no', 'change_to_yes')\n",
    "\n",
    "main_df['is_repaired'] = main_df['is_repaired'].replace('change_to_yes', 'yes')\n",
    "main_df['is_repaired'] = main_df['is_repaired'].replace('change_to_no', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, this column has null values, which I will now replace with the word \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['is_repaired'] = main_df['is_repaired'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    350444\n",
       "Name: number_of_pictures, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['number_of_pictures'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is bizarre... I honestly have no idea how it can be that none of the 350,444 cars have any pictures. Whatever the reason, this column is completely useless for my models because if all of the values are 0, then the models cannot use the values of this column to make predictions about the value of a particular used car. The next line drops this column from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.drop('number_of_pictures', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    350444.000000\n",
       "mean       4442.910234\n",
       "std        4519.722739\n",
       "min           0.000000\n",
       "25%        1100.000000\n",
       "50%        2750.000000\n",
       "75%        6480.000000\n",
       "max       20000.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is at least one used car in the dataframe that, for one reason or another, is worth 0 euros. I wonder how many there are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of vehicles in the dataframe that are worth 0 euros is 10017\n"
     ]
    }
   ],
   "source": [
    "print('The number of vehicles in the dataframe that are worth 0 euros is', len(main_df[main_df['price'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that some of the vehicles are not worth anything because they are probably in incredibly poor condition and/or otherwise undesirable.\n",
    "\n",
    "In the event that a customer's car is worth 0 euros, the best the customer can do is donate the car for scrap parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     35096\n",
       "1     22991\n",
       "2     21190\n",
       "3     34223\n",
       "4     29132\n",
       "5     29017\n",
       "6     31323\n",
       "7     27071\n",
       "8     22494\n",
       "9     23709\n",
       "10    25983\n",
       "11    24065\n",
       "12    24150\n",
       "Name: registration_month, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['registration_month'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it intriguing that there are not 12, but 13 distinct month values. I will leave this column alone because there is probably a good reason for this that I am unaware of. For example, maybe 1 refers to January, 2 refers to February, 3 refers to March, etc. whereas 0 means \"the registration month value is unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    350444.000000\n",
       "mean       2003.727554\n",
       "std          61.510710\n",
       "min        1000.000000\n",
       "25%        1999.000000\n",
       "50%        2003.000000\n",
       "75%        2008.000000\n",
       "max        9999.000000\n",
       "Name: registration_year, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['registration_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column has at least two cars with blatantly incorrect registration year values. At least one car was apparently registered in the year 1000, a year in which cars did not exist yet, and at least one car was apparently registered in the year 9999, which has not happened yet. How many strange registration year values does this dataframe have?\n",
    "\n",
    "I am completing this project in December 2023, and I wonder which year is the most recent registration year that Rusty Bargain has in its dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has...\n",
      "9297 cars with registration year 2016,\n",
      "10119 cars with registration year 2017,\n",
      "3812 cars with registration year 2018,\n",
      "19 cars with registration year 2019,\n",
      "0 cars with registration year 2020,\n",
      "0 cars with registration year 2021,\n",
      "0 cars with registration year 2022,\n",
      "and 0 cars with registration year 2023.\n"
     ]
    }
   ],
   "source": [
    "print('The dataframe has...')\n",
    "print(len(main_df[main_df['registration_year'] == 2016]), 'cars with registration year 2016,')\n",
    "print(len(main_df[main_df['registration_year'] == 2017]), 'cars with registration year 2017,')\n",
    "print(len(main_df[main_df['registration_year'] == 2018]), 'cars with registration year 2018,')\n",
    "print(len(main_df[main_df['registration_year'] == 2019]), 'cars with registration year 2019,')\n",
    "print(len(main_df[main_df['registration_year'] == 2020]), 'cars with registration year 2020,')\n",
    "print(len(main_df[main_df['registration_year'] == 2021]), 'cars with registration year 2021,')\n",
    "print(len(main_df[main_df['registration_year'] == 2022]), 'cars with registration year 2022,')\n",
    "print('and', len(main_df[main_df['registration_year'] == 2023]), 'cars with registration year 2023.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the most recent registration year present in the dataframe is 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cars in the dataframe that somehow have a registration year of 2024 or later is 66\n"
     ]
    }
   ],
   "source": [
    "print('The number of cars in the dataframe that somehow have a registration year of 2024 or later is', \n",
    "      len(main_df[main_df['registration_year'] >= 2024]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be time-consuming and difficult to find the correct registration year of these 66 vehicles. Thankfully, 66 is a small number compared to the total number of vehicles in the dataframe, so I can drop those 66 rows without harming my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df[main_df['registration_year'] < 2024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for registration year values that are clearly too old, according to [THIS](https://simple.wikipedia.org/wiki/History_of_the_automobile) Wikipedia article, it was in 1908 that Henry Ford began producing cars that even commoners could afford to drive. Therefore, no car with a registration year earlier than 1908 should be kept in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cars in the dataframe that somehow have a registration year of 1907 or earlier is 38\n"
     ]
    }
   ],
   "source": [
    "print('The number of cars in the dataframe that somehow have a registration year of 1907 or earlier is', \n",
    "      len(main_df[main_df['registration_year'] <= 1907]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, 38 is a small number compared to the total number of vehicles in the dataframe, so I can drop those 38 rows without harming my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df[main_df['registration_year'] > 1907]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sedan          91336\n",
       "small          79526\n",
       "wagon          65027\n",
       "unknown        34397\n",
       "bus            28734\n",
       "convertible    20156\n",
       "coupe          16134\n",
       "suv            11976\n",
       "other           3054\n",
       "Name: vehicle_type, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['vehicle_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see nothing unusual with this column. It does not surprised me that some vehicle types are (much) more common than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the Dataframe** <a id=3.3></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 350340 entries, 0 to 354106\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   brand               350340 non-null  object        \n",
      " 1   date_crawled        350340 non-null  datetime64[ns]\n",
      " 2   date_created        350340 non-null  datetime64[ns]\n",
      " 3   fuel_type           350340 non-null  object        \n",
      " 4   gear_box            350340 non-null  object        \n",
      " 5   horsepower          350340 non-null  float64       \n",
      " 6   last_seen           350340 non-null  datetime64[ns]\n",
      " 7   mileage             350340 non-null  int64         \n",
      " 8   model               350340 non-null  object        \n",
      " 9   is_repaired         350340 non-null  object        \n",
      " 10  postal_code         350340 non-null  int64         \n",
      " 11  registration_month  350340 non-null  int64         \n",
      " 12  registration_year   350340 non-null  int64         \n",
      " 13  vehicle_type        350340 non-null  object        \n",
      " 14  price               350340 non-null  int64         \n",
      "dtypes: datetime64[ns](3), float64(1), int64(5), object(6)\n",
      "memory usage: 42.8+ MB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the preprocessing I did, the dataframe has gone from having 354,369 rows to 350,340 which, thankfully, is a less than 1.5% decrease. I still have an ample amount of data to build accurate machine learning models with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, the **horsepower** column now has Dtype float64. The next line converts the column back to Dtype int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['horsepower'] = main_df['horsepower'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now make a new dataframe called **main_df_encoded**, which is an encoded version of **main_df**. As mentioned earlier, I will not use the columns **date_crawled**, **date_created**, **last_seen**, and **postal_code** to train the models, so they will not be included in **main_df_encoded**. \n",
    "\n",
    "Furthermore, I will use an **OrdinalEncoder** on all of the categorical features because machine learning models cannot handle categorical values such as \"bmw\", \"gasoline\", \"automatic\", \"golf\", \"yes\", and \"sedan\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>gear_box</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>mileage</th>\n",
       "      <th>model</th>\n",
       "      <th>is_repaired</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320807</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>150000</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49986</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102</td>\n",
       "      <td>150000</td>\n",
       "      <td>223.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77271</th>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>150000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>38.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>150000</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216156</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143</td>\n",
       "      <td>150000</td>\n",
       "      <td>203.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332211</th>\n",
       "      <td>38.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "      <td>150000</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>7.0</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193588</th>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140</td>\n",
       "      <td>150000</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102201</th>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>125000</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59284</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105</td>\n",
       "      <td>150000</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87032</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>150000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand  fuel_type  gear_box  horsepower  mileage  model  is_repaired  \\\n",
       "320807   10.0        6.0       1.0          60   150000  102.0          1.0   \n",
       "49986    38.0        2.0       1.0         102   150000  223.0          2.0   \n",
       "77271    27.0        6.0       1.0          75   150000   75.0          2.0   \n",
       "2669     38.0        7.0       1.0          75   150000  116.0          0.0   \n",
       "216156   38.0        2.0       1.0         143   150000  203.0          2.0   \n",
       "332211   38.0        7.0       2.0          50   150000  143.0          1.0   \n",
       "193588   27.0        6.0       1.0         140   150000  149.0          1.0   \n",
       "102201   38.0        6.0       2.0          60   125000  173.0          1.0   \n",
       "59284    38.0        2.0       1.0         105   150000  116.0          2.0   \n",
       "87032    24.0        6.0       1.0          75   150000   42.0          2.0   \n",
       "\n",
       "        registration_month  registration_year  vehicle_type  price  \n",
       "320807                   1               1997           4.0    250  \n",
       "49986                    5               2006           0.0   8490  \n",
       "77271                    4               2002           5.0   1499  \n",
       "2669                     0               1995           7.0    150  \n",
       "216156                  12               2006           0.0   7750  \n",
       "332211                   5               2005           7.0    999  \n",
       "193588                   0               2005           1.0   3800  \n",
       "102201                   7               1999           5.0   1600  \n",
       "59284                    1               2007           4.0   6900  \n",
       "87032                    1               2000           8.0   1200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_features = ['brand', 'fuel_type', 'gear_box', 'model', 'is_repaired', 'vehicle_type']\n",
    "\n",
    "main_df_encoded = main_df.drop(['date_crawled', 'date_created', 'last_seen', 'postal_code'], axis = 1).copy()\n",
    "\n",
    "categorical_encoder = OrdinalEncoder()\n",
    "\n",
    "main_df_encoded[categorical_features] = categorical_encoder.fit_transform(main_df_encoded[categorical_features])\n",
    "\n",
    "display(main_df_encoded.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the features are all quantitative, I will also use a **MaxAbsScaler** on the features (but not the target, **price**) to scale their values so that no one feature dominates the others. (In particular, the **mileage** column would dominate if I did not do this since those values are, on average, especially large.) However, this should be done after I split the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training <a id=4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the dataframe into three sets: training, validation, and test, using the commonly used ratio 60:20:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_set = train_test_split(main_df_encoded, test_size = 0.2, random_state = 12345)\n",
    "\n",
    "features_test = test_set.copy().drop(columns = 'price')\n",
    "target_test = test_set['price'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df_encoded_not_test = main_df_encoded.copy().drop(features_test.index)\n",
    "\n",
    "training_set, validation_set = train_test_split(main_df_encoded_not_test, test_size = 0.25, random_state = 12345)\n",
    "\n",
    "features_train = training_set.copy().drop(columns = 'price')\n",
    "target_train = training_set['price'].copy()\n",
    "\n",
    "features_valid = validation_set.copy().drop(columns = 'price')\n",
    "target_valid = validation_set['price'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can use a **MaxAbsScaler** on the quantitative features of the **features_train** and **features_test** dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_col = ['brand', 'fuel_type', 'gear_box', 'horsepower', 'mileage', 'model', \n",
    "                'is_repaired', 'registration_month', 'registration_year', 'vehicle_type']\n",
    "\n",
    "quantitative_encoder = MaxAbsScaler().fit(features_train[features_col].to_numpy())\n",
    "\n",
    "features_train.loc[:, features_col] = quantitative_encoder.transform(features_train[features_col].to_numpy())\n",
    "features_valid.loc[:, features_col] = quantitative_encoder.transform(features_valid[features_col].to_numpy())\n",
    "features_test.loc[:, features_col] = quantitative_encoder.transform(features_test[features_col].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am ready to make my linear regression, decision tree, and random forest models. \n",
    "\n",
    "I mentioned earlier that linear regression is not very good for hyperparameter tuning, so my linear regression model will serve as my dummy model, thereby giving me a convenient way to perform a sanity check on my other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Model** <a id=4.1></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62 ms, sys: 20.3 ms, total: 82.3 ms\n",
      "Wall time: 92.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.13 ms, sys: 20.2 ms, total: 25.3 ms\n",
      "Wall time: 8.49 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_lr_model = lr_model.predict(features_valid)\n",
    "valid_rmse_lr_model = mean_squared_error(target_valid, valid_pred_lr_model) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the linear regression model is 3015\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the linear regression model is', int(valid_rmse_lr_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean square error in predicting the prices is a little more than 3,000 euros, which I worry is a rather big error. On the bright side, it is great to see that the validation set and the test set acquired very similar results! The similar results imply that the splits were done correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Model, No Hyperparameter Tuning** <a id=4.2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 27.9 ms, total: 1.37 s\n",
      "Wall time: 1.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=12345)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dt_model_no_ht = DecisionTreeRegressor(random_state = 12345)\n",
    "dt_model_no_ht.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.1 ms, sys: 0 ns, total: 43.1 ms\n",
      "Wall time: 41.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_dt_model_no_ht = dt_model_no_ht.predict(features_valid)\n",
    "valid_rmse_dt_model_no_ht = mean_squared_error(target_valid, valid_pred_dt_model_no_ht) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the DEFAULT decision tree model is 2304\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the DEFAULT decision tree model is', \n",
    "      int(valid_rmse_dt_model_no_ht))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the validation set and the test set acquired very similar results. Furthermore, as expected, the decision tree model is significantly better than the linear regression. More specifically, the RMSE of the decision tree model is close to 25% smaller, meaning it more accurately predicts the prices of used cars than the linear regression. Let's see if hyperparameter tuning can significantly decrease the RMSE even more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Model, With Hyperparameter Tuning** <a id=4.3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the next line is code that uses a RandomizedSearchCV to help me find hyperparameter values for the decision tree model that are better than using the default values. I deliberately have the code commented out because running it would slow down the Jupyter notebook. That said, thanks to a combination of using the RandomizedSearchCV and trial & error I found good hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters_dt_model = {'max_depth': randint(1, 31),\n",
    "#                            'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "#                            'min_samples_leaf': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]}\n",
    "\n",
    "#grid_search_dt_model = RandomizedSearchCV(estimator = DecisionTreeRegressor(), \n",
    "#                                          param_distributions = hyperparameters_dt_model,\n",
    "#                                          scoring = 'neg_root_mean_squared_error', \n",
    "#                                          cv = 3, n_iter = 50)\n",
    "\n",
    "#grid_search_dt_model.fit(features_train, target_train)\n",
    "\n",
    "#print(grid_search_dt_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 988 ms, sys: 3.75 ms, total: 992 ms\n",
      "Wall time: 996 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=20, min_samples_leaf=10, min_samples_split=4,\n",
       "                      random_state=12345)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dt_model_tuned = DecisionTreeRegressor(random_state = 12345, max_depth = 20, min_samples_leaf = 10, min_samples_split = 4)\n",
    "dt_model_tuned.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 ms, sys: 3.8 ms, total: 22.8 ms\n",
      "Wall time: 23.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_dt_model_tuned = dt_model_tuned.predict(features_valid)\n",
    "valid_rmse_dt_model_tuned = mean_squared_error(target_valid, valid_pred_dt_model_tuned) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the TUNED decision tree model is 1975\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the TUNED decision tree model is', \n",
    "      int(valid_rmse_dt_model_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting **max_depth** = 20, **min_samples_leaf** = 10, and **min_samples_split** = 4 the RMSE has been reduced by more than 300, a significant improvement for sure! Furthermore, the wall time has been reduced as well! I wonder how a random forest will do..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model, No Hyperparameter Tuning** <a id=4.4></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 560 ms, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=12345)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_model_no_ht = RandomForestRegressor(random_state = 12345)\n",
    "rf_model_no_ht.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.56 s, sys: 7.94 ms, total: 3.57 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_rf_model_no_ht = rf_model_no_ht.predict(features_valid)\n",
    "valid_rmse_rf_model_no_ht = mean_squared_error(target_valid, valid_pred_rf_model_no_ht) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the DEFAULT random forest model is 1771\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the DEFAULT random forest model is', \n",
    "      int(valid_rmse_rf_model_no_ht))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the bright side, the RMSE of the random forest model is even smaller than the decision tree model, and a little more than 40% lower compared to the linear regression. However, this model takes <b><u>FAR</b></u> longer than the decision tree to process. The wall time of the decision tree is less than 2 seconds, whereas the wall time of the random forest is more than 1 <b><i>minute</b></i>! I wonder if hyperparameter tuning can decrease both the RMSE (even more) and the wall time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model, With Hyperparameter Tuning** <a id=4.5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with the decision tree model, the next line is code uses a RandomizedSearchCV to help me find hyperparameter values for the random forest model that are better than using the default values. Once more, I deliberately have the code commented out because running it would slow down the Jupyter notebook. After acquiring the best hyperparameter values according to RandomizedSearchCV, I once again did some trial & error to tweak the model a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters_rf_model = {'max_depth': randint(1, 21),\n",
    "#                            'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "#                            'min_samples_leaf': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "#                            'n_estimators': randint(1, 31)}\n",
    "\n",
    "#grid_search_rf_model = RandomizedSearchCV(estimator = RandomForestRegressor(), \n",
    "#                                          param_distributions = hyperparameters_rf_model,\n",
    "#                                          scoring = 'neg_root_mean_squared_error', \n",
    "#                                          cv = 3, n_iter = 10)\n",
    "\n",
    "#grid_search_rf_model.fit(features_train, target_train)\n",
    "\n",
    "#print(grid_search_rf_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 39.8 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, min_samples_leaf=2, min_samples_split=8,\n",
       "                      n_estimators=25, random_state=12345)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_model_tuned = RandomForestRegressor(random_state = 12345, max_depth = 20, n_estimators = 25,\n",
    "                                       min_samples_leaf = 2, min_samples_split = 8)\n",
    "\n",
    "rf_model_tuned.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 492 ms, sys: 0 ns, total: 492 ms\n",
      "Wall time: 503 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_rf_model_tuned = rf_model_tuned.predict(features_valid)\n",
    "valid_rmse_rf_model_tuned = mean_squared_error(target_valid, valid_pred_rf_model_tuned) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the TUNED random forest model is 1767\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the TUNED random forest model is', \n",
    "      int(valid_rmse_rf_model_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am honestly very surprised to see that the RMSE values of the tuned random forest model are only a tiny bit better than those of the default random forest. That said, the wall time is now **MUCH** shorter, about 20 seconds instead of over 1 minute.\n",
    "\n",
    "Unfortunately, I still don't think that this improved wall time is particularly good. Thankfully, I recently learned about three other models that I can test out, whose names are CatBoostRegressor, LGBMRegressor, and XGBRegressor. If any of those three acquire RMSE values that are even smaller than those of the tuned random forest while also having a smaller wall time than the tuned random forest, that would be ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost Regressor, No Hyperparameter Tuning** <a id=4.6></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.095314\n",
      "0:\tlearn: 4253.3917925\ttotal: 100ms\tremaining: 1m 39s\n",
      "100:\tlearn: 1923.2443937\ttotal: 4.6s\tremaining: 41s\n",
      "200:\tlearn: 1835.3314705\ttotal: 9.1s\tremaining: 36.2s\n",
      "300:\tlearn: 1787.6560480\ttotal: 13.6s\tremaining: 31.6s\n",
      "400:\tlearn: 1756.3402414\ttotal: 18.1s\tremaining: 27.1s\n",
      "500:\tlearn: 1731.9435852\ttotal: 22.7s\tremaining: 22.6s\n",
      "600:\tlearn: 1711.4408302\ttotal: 27.1s\tremaining: 18s\n",
      "700:\tlearn: 1694.3209699\ttotal: 31.6s\tremaining: 13.5s\n",
      "800:\tlearn: 1679.4697128\ttotal: 36.1s\tremaining: 8.96s\n",
      "900:\tlearn: 1665.9959758\ttotal: 40.5s\tremaining: 4.45s\n",
      "999:\tlearn: 1654.3790547\ttotal: 44.9s\tremaining: 0us\n",
      "CPU times: user 45 s, sys: 51.5 ms, total: 45.1 s\n",
      "Wall time: 45.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f5286099370>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cb_model_no_ht = CatBoostRegressor(random_state = 12345)\n",
    "cb_model_no_ht.fit(features_train, target_train, verbose = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 90.9 ms, sys: 26 µs, total: 90.9 ms\n",
      "Wall time: 89.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_cb_model_no_ht = cb_model_no_ht.predict(features_valid)\n",
    "valid_rmse_cb_model_no_ht = mean_squared_error(target_valid, valid_pred_cb_model_no_ht) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the DEFAULT CatBoost regressor is 1768\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the DEFAULT CatBoost regressor is', \n",
    "      int(valid_rmse_cb_model_no_ht))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These RMSE values are extremely similar to those of the random forest models. Let's see if hyperparameter tuning changes this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost Regressor, With Hyperparameter Tuning** <a id=4.7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, I use GridSearchCV instead of RandomizedSearchCV because I did not make there be as many possible combinations to go through, so it would not be overly time-consuming to check all of them and find out which is the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters_cb_model = {'depth': [5, 10],\n",
    "#                            'iterations': [100, 150, 200, 250],\n",
    "#                            'learning_rate': [0.1, 0.2]}\n",
    "\n",
    "\n",
    "#grid_search_cb_model = GridSearchCV(estimator = CatBoostRegressor(), \n",
    "#                                    param_grid = hyperparameters_cb_model,\n",
    "#                                    scoring = 'neg_root_mean_squared_error', cv = 3)\n",
    "\n",
    "#grid_search_cb_model.fit(features_train, target_train, verbose = 100)\n",
    "\n",
    "#print(grid_search_cb_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3901.9834751\ttotal: 140ms\tremaining: 34.8s\n",
      "50:\tlearn: 1776.5429646\ttotal: 6.82s\tremaining: 26.6s\n",
      "100:\tlearn: 1677.8302034\ttotal: 13.4s\tremaining: 19.7s\n",
      "150:\tlearn: 1610.6310353\ttotal: 19.9s\tremaining: 13s\n",
      "200:\tlearn: 1565.8076164\ttotal: 26.4s\tremaining: 6.44s\n",
      "249:\tlearn: 1526.8097073\ttotal: 32.8s\tremaining: 0us\n",
      "CPU times: user 32.8 s, sys: 63.8 ms, total: 32.8 s\n",
      "Wall time: 33.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f52860b4be0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cb_model_tuned = CatBoostRegressor(random_state = 12345, depth = 10, iterations = 250, learning_rate = 0.2)\n",
    "cb_model_tuned.fit(features_train, target_train, verbose = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.8 ms, sys: 3.98 ms, total: 88.8 ms\n",
      "Wall time: 98.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_cb_model_tuned = cb_model_tuned.predict(features_valid)\n",
    "valid_rmse_cb_model_tuned = mean_squared_error(target_valid, valid_pred_cb_model_tuned) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the TUNED CatBoost regressor is 1739\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the TUNED CatBoost regressor is', \n",
    "      int(valid_rmse_cb_model_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the CatBoost regressor made the RMSE values a little better, and the wall time is a little reduced. The tuned CatBoost regressor has RMSE values that are slightly better than the tuned random forest, but the wall time is over 10 seconds longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM Regressor, No Hyperparameter Tuning** <a id=4.8></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.39 s, sys: 40 ms, total: 3.43 s\n",
      "Wall time: 3.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(random_state=12345)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_model_no_ht = LGBMRegressor(random_state = 12345)\n",
    "lgbm_model_no_ht.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 641 ms, sys: 4 µs, total: 641 ms\n",
      "Wall time: 615 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_lgbm_model_no_ht = lgbm_model_no_ht.predict(features_valid)\n",
    "valid_rmse_lgbm_model_no_ht = mean_squared_error(target_valid, valid_pred_lgbm_model_no_ht) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the DEFAULT LightGBM regressor is 1851\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the DEFAULT LightGBM regressor is', \n",
    "      int(valid_rmse_lgbm_model_no_ht))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These RMSE values are in between those of the tuned random forest and the tuned decision tree. This default LightGBM model has a noticeably larger wall time value than the tuned decision tree, but thankfully it is much smaller than the wall time of the tuned random forest, which suggests to me that using a tuned LightGBM model has potential to be one that strikes an excellent balance between speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM Regressor, With Hyperparameter Tuning** <a id=4.9></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters_lgbm_model = {'max_depth': [5, 10],\n",
    "#                              'n_estimators': [50, 100, 150, 200],\n",
    "#                              'learning_rate': [0.1, 0.2]}\n",
    "\n",
    "\n",
    "#grid_search_lgbm_model = GridSearchCV(estimator = LGBMRegressor(), \n",
    "#                                      param_grid = hyperparameters_lgbm_model,\n",
    "#                                      scoring = 'neg_root_mean_squared_error', cv = 3)\n",
    "\n",
    "#grid_search_lgbm_model.fit(features_train, target_train)\n",
    "\n",
    "#print(grid_search_lgbm_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.75 s, sys: 43.8 ms, total: 4.8 s\n",
      "Wall time: 4.87 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.2, max_depth=10, n_estimators=200,\n",
       "              random_state=12345)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_model_tuned = LGBMRegressor(random_state = 12345, max_depth = 10, n_estimators = 200, learning_rate = 0.2)\n",
    "lgbm_model_tuned.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 968 ms, sys: 7.9 ms, total: 976 ms\n",
      "Wall time: 998 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_lgbm_model_tuned = lgbm_model_tuned.predict(features_valid)\n",
    "valid_rmse_lgbm_model_tuned = mean_squared_error(target_valid, valid_pred_lgbm_model_tuned) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the TUNED LightGBM regressor is 1764\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the TUNED LightGBM regressor is', \n",
    "      int(valid_rmse_lgbm_model_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great result! The tuned LightGBM regressor has RMSE values that are slightly better than the tuned random forest, and its wall time is less than half that of the tuned random forest! More specifically, the tuned LightGBM regressor has a wall time greater than 5 seconds, but less than 10. Though the wall time of the tuned LightGBM regressor is noticeably longer than that of the tuned decision tree, I personally think the additional time is worth it because the tuned LightGBM regressor has RMSE values that are a little more than 200 (euros) smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB Regressor, No Hyperparameter Tuning** <a id=4.10></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 56.6 ms, total: 30.1 s\n",
      "Wall time: 30.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=12345,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgbr_model_no_ht = XGBRegressor(random_state = 12345)\n",
    "xgbr_model_no_ht.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 354 ms, sys: 3.99 ms, total: 358 ms\n",
      "Wall time: 362 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_xgbr_model_no_ht = xgbr_model_no_ht.predict(features_valid)\n",
    "valid_rmse_xgbr_model_no_ht = mean_squared_error(target_valid, valid_pred_xgbr_model_no_ht) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the DEFAULT XGB regressor is 1781\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the DEFAULT XGB regressor is', \n",
    "      int(valid_rmse_xgbr_model_no_ht))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not fond of the fact that the wall time is about 30 seconds, which is longer than the tuned random forest despite having similar RMSE values. With that said, the decision tree model (in particular) was greatly improved thanks to tuning the hyperparameters, and if that is the case for the XGB regressor as well, then it might be even better to use than the tuned LightGBM regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB Regressor, With Hyperparameter Tuning** <a id=4.11></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters_xgbr_model = {'max_depth': [5, 10],\n",
    "#                              'n_estimators': [25, 50, 75, 100],\n",
    "#                              'learning_rate': [0.1, 0.2]}\n",
    "\n",
    "\n",
    "#grid_search_xgbr_model = GridSearchCV(estimator = XGBRegressor(), \n",
    "#                                      param_grid = hyperparameters_xgbr_model,\n",
    "#                                      scoring = 'neg_root_mean_squared_error', cv = 3)\n",
    "\n",
    "#grid_search_xgbr_model.fit(features_train, target_train)\n",
    "\n",
    "#print(grid_search_xgbr_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.4 s, sys: 87.9 ms, total: 58.5 s\n",
      "Wall time: 59.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
       "             max_depth=10, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=12345,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgbr_model_tuned = XGBRegressor(random_state = 12345, max_depth = 10, n_estimators = 100, learning_rate = 0.2)\n",
    "xgbr_model_tuned.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 692 ms, sys: 51 µs, total: 692 ms\n",
      "Wall time: 682 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_pred_xgbr_model_tuned = xgbr_model_tuned.predict(features_valid)\n",
    "valid_rmse_xgbr_model_tuned = mean_squared_error(target_valid, valid_pred_xgbr_model_tuned) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the validation set using the TUNED XGB regressor is 1713\n"
     ]
    }
   ],
   "source": [
    "print('The root mean square error of the validation set using the TUNED XGB regressor is', \n",
    "      int(valid_rmse_xgbr_model_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBR model is not worth using. Though I managed to trim down the RMSE values a bit (by less than 100), using hyperparameter tuning is not worth it with this model because it causes the wall time to approximately double. I would not want to use the default XGBR model either because I see no advantages to using it over the tuned decision tree, the tuned random forest, and the tuned LightGBM regressor models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis <a id=5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the above RMSE values into a new dataframe. Furthermore, I would also like for the dataframe to indicate whether or not the wall time is less than 30 seconds. My reasoning for this is, from my perspective, a wall time greater than 30 seconds is too slow. A wall time less than 10 seconds would be ideal, but a wall time between 10 seconds and 30 seconds is acceptable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame()\n",
    "\n",
    "summary_df['model_name'] = ['linear_reg', 'dt_default', 'dt_tuned', 'rf_default', 'rf_tuned','cat_default', \n",
    "                            'cat_tuned', 'light_default', 'light_tuned', 'xgbr_default', 'xgbr_tuned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['time_under_30'] = ['Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['rmse'] = [int(valid_rmse_lr_model), int(valid_rmse_dt_model_no_ht), int(valid_rmse_dt_model_tuned),\n",
    "                      int(valid_rmse_rf_model_no_ht), int(valid_rmse_rf_model_tuned), int(valid_rmse_cb_model_no_ht), \n",
    "                      int(valid_rmse_cb_model_tuned), int(valid_rmse_lgbm_model_no_ht), int(valid_rmse_lgbm_model_tuned), \n",
    "                      int(valid_rmse_xgbr_model_no_ht), int(valid_rmse_xgbr_model_tuned)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, any model whose wall time is more than 30 seconds should not even be considered because there are multiple models whose wall time is under 30 seconds **AND** that have relatively low RMSE values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_under_30 = summary_df[summary_df['time_under_30'] == 'Yes'].copy()\n",
    "summary_df_under_30 = summary_df_under_30.drop('time_under_30', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the linear regression is being used as the dummy model. Hence, I think it is appropriate to add a column to this dataframe that tells how much less the average RMSE value of each model is compared to that of the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_under_30['rmse_minus_lr_rmse'] = summary_df_under_30['rmse'] - int(valid_rmse_lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add a column that expresses how much less the average RMSE value of each model is compared to that of the linear regression as a <u>percentage</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_under_30['perc_dec_from_lr'] = round((summary_df_under_30['rmse'] - int(valid_rmse_lr_model)) \n",
    "                                                / int(valid_rmse_lr_model) * 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rmse_minus_lr_rmse</th>\n",
       "      <th>perc_dec_from_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear_reg</td>\n",
       "      <td>3015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_default</td>\n",
       "      <td>2304</td>\n",
       "      <td>-711</td>\n",
       "      <td>-23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_tuned</td>\n",
       "      <td>1975</td>\n",
       "      <td>-1040</td>\n",
       "      <td>-34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf_tuned</td>\n",
       "      <td>1767</td>\n",
       "      <td>-1248</td>\n",
       "      <td>-41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>light_default</td>\n",
       "      <td>1851</td>\n",
       "      <td>-1164</td>\n",
       "      <td>-38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>light_tuned</td>\n",
       "      <td>1764</td>\n",
       "      <td>-1251</td>\n",
       "      <td>-41.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  rmse  rmse_minus_lr_rmse  perc_dec_from_lr\n",
       "0     linear_reg  3015                   0               0.0\n",
       "1     dt_default  2304                -711             -23.6\n",
       "2       dt_tuned  1975               -1040             -34.5\n",
       "4       rf_tuned  1767               -1248             -41.4\n",
       "7  light_default  1851               -1164             -38.6\n",
       "8    light_tuned  1764               -1251             -41.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(summary_df_under_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to this dataframe, I am even more convinced that the tuned LightGBM Regressor is the best one to use. That model is relatively fast, and its RMSE value is the biggest decrease from the linear regression's RMSE value. \n",
    "\n",
    "One last thing I would like to do is assess the tuned LightGBM Regressor using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square error of the test set using the TUNED LightGBM regressor is 1774\n"
     ]
    }
   ],
   "source": [
    "test_pred_lgbm_model_tuned = lgbm_model_tuned.predict(features_test)\n",
    "test_rmse_lgbm_model_tuned = mean_squared_error(target_test, test_pred_lgbm_model_tuned) ** 0.5\n",
    "\n",
    "print('The root mean square error of the test set using the TUNED LightGBM regressor is', int(test_rmse_lgbm_model_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! This RMSE value is very similar to the value I acquired using the validation set, which is exactly what should happen if the model is works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a id=6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain hopes to attract new customers using an app that is intended to quickly determine the market value of a prospective customer's used car. \n",
    "\n",
    "My responsibility was to build a model for the app that predicts the prices of used cars quickly and accurately, while also making sure that the model does not take too long to train.\n",
    "\n",
    "To help me build such a model, I tested each of the following regressors, both with and without hyperparameter tuning: decision tree, random forest, CatBoost, LightGBM, and and XGBR.\n",
    "\n",
    "I narrowed down the options to the models where the combined wall time between training the model and making predictions is less than 30 seconds, and from there looked to see which one had the smallest root mean square error, based on the results of using the validation set on the models.\n",
    "\n",
    "I confidently conclude that the hyperparameter tuned LightGBM model is the best one to use, as it has a combined wall time of under 10 seconds, and the smallest RMSE value. The tuned Decision Tree model is faster, but less accurate, and the tuned Random Forest model is approximately as accurate, but more than two times slower. The tuned LightGBM model strikes the best balance between speed and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
